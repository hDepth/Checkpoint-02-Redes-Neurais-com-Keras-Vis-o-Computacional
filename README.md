## ğŸ§  Checkpoint 02 â€” Parte 01 
Redes Neurais com Keras (ClassificaÃ§Ã£o + RegressÃ£o)

Este projeto faz parte do Checkpoint 02 da disciplina Disruptive Architectures: IoT, IoB e Generative AI.
O objetivo desta etapa Ã© treinar redes neurais com Keras, comparar com modelos clÃ¡ssicos do Scikit-learn e analisar os resultados obtidos.

## ğŸ“ Estrutura da Pasta
parte01-redes-neurais/  
â”œâ”€â”€ classificacao_wine.ipynb        # ExercÃ­cio 1 - ClassificaÃ§Ã£o Multiclasse  
â”œâ”€â”€ regressao_california.ipynb      # ExercÃ­cio 2 - RegressÃ£o  
â””â”€â”€ README.md                        

## ğŸ§ª 1. ExercÃ­cio 1 â€“ ClassificaÃ§Ã£o Multiclasse ğŸ·

# ğŸ“Š Dataset: Wine Dataset (UCI)

Objetivo: Classificar vinhos em 3 classes com base em caracterÃ­sticas quÃ­micas.

Rede Neural:

2 camadas ocultas (32 neurÃ´nios, ReLU)

Camada de saÃ­da (3 neurÃ´nios, Softmax)

Otimizador: Adam

Perda: categorical_crossentropy

Modelo de comparaÃ§Ã£o: RandomForestClassifier (Scikit-learn)

MÃ©trica avaliada: AcurÃ¡cia

# âœ… Resultados esperados:

Rede Neural e RandomForest atingem acurÃ¡cias altas (acima de 0.95).

RandomForest costuma performar muito bem em dados tabulares pequenos.

## ğŸ§® 2. ExercÃ­cio 2 â€“ RegressÃ£o ğŸ¡

# ğŸ“Š Dataset: California Housing Dataset (Scikit-learn)

Objetivo: Prever o valor mÃ©dio das casas na CalifÃ³rnia com base em dados demogrÃ¡ficos e geogrÃ¡ficos.

Rede Neural:

3 camadas ocultas (64, 32 e 16 neurÃ´nios, ReLU)

Camada de saÃ­da (1 neurÃ´nio, Linear)

Otimizador: Adam

Perda: MSE

Modelos de comparaÃ§Ã£o:

LinearRegression

RandomForestRegressor

MÃ©trica avaliada: Erro MÃ©dio Absoluto (MAE)

# âœ… Resultados esperados:

Rede Neural apresenta erro competitivo em relaÃ§Ã£o aos modelos clÃ¡ssicos.

RandomForest costuma ter melhor desempenho direto em dados tabulares.

## ğŸ§° 3. Como Executar os Notebooks (Google Colab)

Acesse Google Colab

FaÃ§a upload dos notebooks:

classificacao_wine.ipynb

regressao_california.ipynb

Clique em â€œCopiar para o Driveâ€ para salvar.

Execute todas as cÃ©lulas (Ctrl + F9) â€” nÃ£o Ã© necessÃ¡rio instalar nada extra, o Colab jÃ¡ vem com TensorFlow e Scikit-learn.

## âš™ï¸ 4. Principais HiperparÃ¢metros
ParÃ¢metro	ClassificaÃ§Ã£o	RegressÃ£o
Ã‰pocas	80	80
Batch size	8	32
Otimizador	Adam	Adam
FunÃ§Ã£o de ativaÃ§Ã£o saÃ­da	Softmax	Linear
FunÃ§Ã£o de perda	Crossentropy	MSE  

## ğŸ“Š 5. ComparaÃ§Ã£o de Desempenho
Modelo	Tarefa	MÃ©trica	Resultado aproximado
Rede Neural (Keras)	ClassificaÃ§Ã£o	AcurÃ¡cia	> 0.95
RandomForestClassifier	ClassificaÃ§Ã£o	AcurÃ¡cia	> 0.95
Rede Neural (Keras)	RegressÃ£o	MAE	~0.35â€“0.45
LinearRegression	RegressÃ£o	MAE	~0.45
RandomForestRegressor	RegressÃ£o	MAE	~0.30â€“0.35

(os valores podem variar um pouco conforme o treinamento)

## ğŸ“ 6. ObservaÃ§Ãµes Finais

Modelos clÃ¡ssicos como RandomForest costumam ter Ã³tima performance em dados tabulares.

Redes neurais oferecem mais flexibilidade para ajustes e aprendizado profundo.

O uso do Colab simplifica a execuÃ§Ã£o por jÃ¡ conter as dependÃªncias instaladas.

O histÃ³rico de treinamento (grÃ¡ficos de acurÃ¡cia e erro) facilita entender a evoluÃ§Ã£o do modelo.
